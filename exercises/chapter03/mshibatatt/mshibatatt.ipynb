{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Deep Value-Based Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. *DQN*\n",
    "Implement DQN from the Stable Baselines on Breakout from Gym. Turn off Dueling and Priorities. Find out what the values are for ùõº, the training rate, for $\\varepsilon$, the exploration rate, what kind of neural network architecture is used, what the replay buffer size is, and how frequently the target network is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python breakout.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Docs of stable-baseline3 DQN library ([here](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html)), default parameters are:\n",
    "- $\\alpha$: 0.0001\n",
    "- $\\varepsilon$: 0.1\n",
    "- Neural network architectute: CNN for input and activatied by ReLu ([here](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html#stable_baselines3.dqn.CnnPolicy))\n",
    "- Replay buffer size: 1000000 \n",
    "- How frequently the target network updated: 4 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. *Hyperparameters*\n",
    "Change all those hyperparameters, up, and down, and note the effect on training speed, and the training outcome: how good is the result? How sensitive is performance to hyperparameter optimization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python breakout.py -lr 1e-5 -show False\n",
    "!python breakout.py -lr 1e-3 -show False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir ./tensorboard/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. *Cloud*\n",
    "Use different computers, experiment with GPU versions to speed up training, consider Colab, AWS, or another cloud provider with fast GPU (or TPU) machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. *Gym*\n",
    "Go to Gym and try different problems. For what kind of problems does DQN work, what are characteristics of problems for which it works less well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. *Stable Baselines*\n",
    "Go to the Stable baselines and implement different agent algorithms. Try Dueling algorithms, Prioritized experience replay, but also other algorithm, such as Actor critic or policy-based. (These algorithms will be explained in the next chapter.) Note their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. *Tensorboard*\n",
    "With Tensorboard you can follow the training process as it progresses. Tensorboard works on log files. Try TensorBoard on a Keras exercise and follow different training indicators. Also try TensorBoard on the Stable Baselines and see which indicators you can follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. *Checkpointing*\n",
    "Long training runs in Keras need checkpointing, to save valuable computations in case of a hardware or software failure. Create a large training job, and setup checkpointing. Test everything by interrupting the training, and try to re-load the pre-trained checkpoint to restart the training where it left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
