{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Deep Value-Based Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. *DQN*\n",
    "Implement DQN from the Stable Baselines on Breakout from Gym. Turn off Dueling and Priorities. Find out what the values are for ùõº, the training rate, for $\\varepsilon$, the exploration rate, what kind of neural network architecture is used, what the replay buffer size is, and how frequently the target network is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Hyperparameters Change all those hyperparameters, up, and down, and note the effect on training speed, and the training outcome: how good is the result? How sensitive is performance to hyperparameter optimization?\n",
    "3. Cloud Use different computers, experiment with GPU versions to speed up training, consider Colab, AWS, or another cloud provider with fast GPU (or TPU) machines.\n",
    "4. Gym Go to Gym and try different problems. For what kind of problems does DQN work, what are characteristics of problems for which it works less well?\n",
    "5. Stable Baselines Go to the Stable baselines and implement different agent algorithms. Try Dueling algorithms, Prioritized experience replay, but also other algorithm, such as Actor critic or policy-based. (These algorithms will be explained in the next chapter.) Note their performance.\n",
    "6. Tensorboard With Tensorboard you can follow the training process as it progresses. Tensorboard works on log files. Try TensorBoard on a Keras exercise and\n",
    "follow different training indicators. Also try TensorBoard on the Stable Baselines and see which indicators you can follow.\n",
    "7. Checkpointing Long training runs in Keras need checkpointing, to save valuable computations in case of a hardware or software failure. Create a large training job, and setup checkpointing. Test everything by interrupting the training, and try to re-load the pre-trained checkpoint to restart the training where it left off."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
