{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Policy-Based Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. *REINFORCE*\n",
    "Go to the [Medium blog](https://medium.com/@ts1829/policy-gradient-reinforcement-learning-inpytorch-df1383ea0baf) and reimplement REINFORCE. You can\n",
    "choose PyTorch, or TensorFlow/Keras, in which case you will have to improvise. Run the algorithm on an environment with a discrete action space, and compare with DQN. Which works better? Run in an environment with a continuous action space. Note that Gym offers a discrete and a continuous version of Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:    17\tRunning reward: 18.00\n",
      "Episode 100\tLast length:   499\tRunning reward: 90.91\n",
      "Episode 200\tLast length:   499\tRunning reward: 243.40\n",
      "Episode 300\tLast length:   499\tRunning reward: 389.91\n",
      "Episode 400\tLast length:   499\tRunning reward: 418.07\n",
      "Episode 500\tLast length:   456\tRunning reward: 434.71\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "# set up for cartpole\n",
    "!python medium.py -t CartPole-v1 -e 600 \n",
    "# TODO: \n",
    "    # 1: prepare DQN and compare by Mountain car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:   199\tRunning reward: -184.16\n",
      "Episode 100\tLast length:   199\tRunning reward: -184.93\n",
      "Episode 200\tLast length:   199\tRunning reward: -186.10\n",
      "Episode 300\tLast length:   199\tRunning reward: -185.68\n",
      "Episode 400\tLast length:   199\tRunning reward: -177.41\n",
      "Episode 500\tLast length:   199\tRunning reward: -170.68\n",
      "Episode 600\tLast length:   199\tRunning reward: -170.63\n",
      "Episode 700\tLast length:   199\tRunning reward: -171.56\n",
      "Episode 800\tLast length:   199\tRunning reward: -179.35\n",
      "Episode 900\tLast length:   199\tRunning reward: -184.24\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "# Cannot clear MontainCar..\n",
    "!python medium.py -t MountainCar-v0 -e 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:   998\tRunning reward: -1.41\n",
      "Episode 100\tLast length:   998\tRunning reward: 0.15\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "!python medium.py -t MountainCarContinuous-v0 -e 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. *Algorithms*\n",
    "Run REINFORCE on a Walker environment from the Baselines. Run DDPG, A3C, and PPO. Run them for different time steps. Make plots. Compare training speed, and outcome quality. Vary hyperparameters to develop an intuition for their effect.\n",
    "## 3. *Suite*\n",
    "Explore the [DeepMind control suite](https://github.com/deepmind/dm_control). Look around and see what environments have been provided, and how you can use them. Consider extending an environment. What learning challenges would you like to introduce? First do a survey of the literature that has been published about the DeepMind control suite."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
