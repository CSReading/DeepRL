{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Policy-Based Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. *REINFORCE*\n",
    "Go to the [Medium blog](https://medium.com/@ts1829/policy-gradient-reinforcement-learning-inpytorch-df1383ea0baf) and reimplement REINFORCE. You can\n",
    "choose PyTorch, or TensorFlow/Keras, in which case you will have to improvise. Run the algorithm on an environment with a discrete action space, and compare with DQN. Which works better? Run in an environment with a continuous action space. Note that Gym offers a discrete and a continuous version of Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:    14\tAverage length: 10.04\n",
      "Episode 50\tLast length:   146\tAverage length: 30.59\n",
      "Episode 100\tLast length:   266\tAverage length: 101.70\n",
      "Episode 150\tLast length:   499\tAverage length: 219.10\n",
      "Episode 200\tLast length:   499\tAverage length: 311.68\n",
      "Episode 250\tLast length:   499\tAverage length: 383.04\n",
      "Episode 300\tLast length:   166\tAverage length: 351.08\n",
      "Episode 350\tLast length:   499\tAverage length: 380.72\n",
      "Episode 400\tLast length:    88\tAverage length: 422.26\n",
      "Episode 450\tLast length:   499\tAverage length: 426.93\n",
      "Episode 500\tLast length:   499\tAverage length: 455.40\n",
      "Episode 550\tLast length:   499\tAverage length: 463.80\n",
      "Episode 600\tLast length:    10\tAverage length: 421.50\n",
      "Episode 650\tLast length:   145\tAverage length: 324.74\n",
      "Episode 700\tLast length:   232\tAverage length: 283.86\n",
      "Episode 750\tLast length:   255\tAverage length: 280.97\n",
      "Episode 800\tLast length:   262\tAverage length: 263.21\n",
      "Episode 850\tLast length:   214\tAverage length: 234.36\n",
      "Episode 900\tLast length:   153\tAverage length: 209.07\n",
      "Episode 950\tLast length:   499\tAverage length: 273.81\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/exercises/chapter04/mshibatatt/medium.py\", line 129, in <module>\n",
      "    show()\n",
      "  File \"/workspace/exercises/chapter04/mshibatatt/medium.py\", line 117, in show\n",
      "    env.render()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gym/core.py\", line 295, in render\n",
      "    return self.env.render(mode, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gym/envs/classic_control/cartpole.py\", line 179, in render\n",
      "    from gym.envs.classic_control import rendering\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/gym/envs/classic_control/rendering.py\", line 27, in <module>\n",
      "    from pyglet.gl import *\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyglet/gl/__init__.py\", line 232, in <module>\n",
      "    import pyglet.window\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyglet/window/__init__.py\", line 1918, in <module>\n",
      "    gl._create_shadow_window()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyglet/gl/__init__.py\", line 206, in _create_shadow_window\n",
      "    _shadow_window = Window(width=1, height=1, visible=False)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyglet/window/xlib/__init__.py\", line 171, in __init__\n",
      "    super(XlibWindow, self).__init__(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyglet/window/__init__.py\", line 590, in __init__\n",
      "    display = pyglet.canvas.get_display()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyglet/canvas/__init__.py\", line 94, in get_display\n",
      "    return Display()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/pyglet/canvas/xlib.py\", line 123, in __init__\n",
      "    raise NoSuchDisplayException('Cannot connect to \"%s\"' % name)\n",
      "pyglet.canvas.xlib.NoSuchDisplayException: Cannot connect to \"None\"\n"
     ]
    }
   ],
   "source": [
    "# set up for cartpole\n",
    "!python medium.py\n",
    "# TODO: compare with DQN by Mountain car\n",
    "    # 1: switch task and check running reward\n",
    "    # 2: apply continuous case\n",
    "    # 3: prepare DQN and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. *Algorithms*\n",
    "Run REINFORCE on a Walker environment from the Baselines. Run DDPG, A3C, and PPO. Run them for different time steps. Make plots. Compare training speed, and outcome quality. Vary hyperparameters to develop an intuition for their effect.\n",
    "## 3. *Suite*\n",
    "Explore the [DeepMind control suite](https://github.com/deepmind/dm_control). Look around and see what environments have been provided, and how you can use them. Consider extending an environment. What learning challenges would you like to introduce? First do a survey of the literature that has been published about the DeepMind control suite."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
