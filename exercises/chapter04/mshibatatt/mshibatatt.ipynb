{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Policy-Based Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. *REINFORCE*\n",
    "Go to the [Medium blog](https://medium.com/@ts1829/policy-gradient-reinforcement-learning-inpytorch-df1383ea0baf) and reimplement REINFORCE. You can\n",
    "choose PyTorch, or TensorFlow/Keras, in which case you will have to improvise. Run the algorithm on an environment with a discrete action space, and compare with DQN. Which works better? Run in an environment with a continuous action space. Note that Gym offers a discrete and a continuous version of Mountain Car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:    14\tRunning reward: 15.00\n",
      "Episode 100\tLast length:   178\tRunning reward: 69.64\n",
      "Episode 200\tLast length:    57\tRunning reward: 90.69\n",
      "Episode 300\tLast length:   151\tRunning reward: 144.67\n",
      "Episode 400\tLast length:   277\tRunning reward: 141.64\n",
      "Episode 500\tLast length:   251\tRunning reward: 255.46\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "# set up for cartpole\n",
    "!python medium.py -t CartPole-v1 -e 600 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:   199\tRunning reward: -184.16\n",
      "Episode 100\tLast length:   199\tRunning reward: -184.93\n",
      "Episode 200\tLast length:   199\tRunning reward: -186.10\n",
      "Episode 300\tLast length:   199\tRunning reward: -185.68\n",
      "Episode 400\tLast length:   199\tRunning reward: -177.41\n",
      "Episode 500\tLast length:   199\tRunning reward: -170.68\n",
      "Episode 600\tLast length:   199\tRunning reward: -170.63\n",
      "Episode 700\tLast length:   199\tRunning reward: -171.56\n",
      "Episode 800\tLast length:   199\tRunning reward: -179.35\n",
      "Episode 900\tLast length:   199\tRunning reward: -184.24\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "# Cannot clear MontainCar..\n",
    "!python medium.py -t MountainCar-v0 -e 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:   998\tRunning reward: -1.26\n",
      "Episode 100\tLast length:   998\tRunning reward: 13.64\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "!python medium.py -t MountainCarContinuous-v0 -e 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:    79\tRunning reward: 80.00\n",
      "Episode 100\tLast length:    12\tRunning reward: 39.35\n",
      "Episode 200\tLast length:    39\tRunning reward: 24.13\n",
      "Episode 300\tLast length:     9\tRunning reward: 19.06\n",
      "Episode 400\tLast length:     8\tRunning reward: 17.19\n",
      "Episode 500\tLast length:     9\tRunning reward: 14.09\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "# too weak..\n",
    "!python DQN.py -t CartPole-v1 -e 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "mean reward: 9.6, s.d. of reward: 0.9165151389911681\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "!python DQN.py -t CartPole-v1 -e 600 -base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tLast length:   199\tRunning reward: -200.00\n",
      "Episode 100\tLast length:   199\tRunning reward: -200.00\n",
      "Episode 200\tLast length:   199\tRunning reward: -200.00\n",
      "Episode 300\tLast length:   199\tRunning reward: -200.00\n",
      "Episode 400\tLast length:   199\tRunning reward: -200.00\n",
      "Episode 500\tLast length:   199\tRunning reward: -200.00\n",
      "Episode 600\tLast length:   199\tRunning reward: -200.00\n",
      "Episode 700\tLast length:   199\tRunning reward: -200.00\n"
     ]
    }
   ],
   "source": [
    "# neither can clear..\n",
    "!python DQN.py -t MountainCar-v0 -e 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n",
      "mean reward: -200.0, s.d. of reward: 0.0\n",
      "libGL error: MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n",
      "MESA-LOADER: failed to retrieve device information\n"
     ]
    }
   ],
   "source": [
    "!python DQN.py -t MountainCar-v0 -e 1000 -base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. *Algorithms*\n",
    "Run REINFORCE on a Walker environment from the Baselines. Run DDPG, A3C, and PPO. Run them for different time steps. Make plots. Compare training speed, and outcome quality. Vary hyperparameters to develop an intuition for their effect.\n",
    "## 3. *Suite*\n",
    "Explore the [DeepMind control suite](https://github.com/deepmind/dm_control). Look around and see what environments have been provided, and how you can use them. Consider extending an environment. What learning challenges would you like to introduce? First do a survey of the literature that has been published about the DeepMind control suite."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
